{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maer3/anaconda/envs/jax-unirep/lib/python3.7/site-packages/jax/lib/xla_bridge.py:119: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "from jax_unirep.utils import get_embeddings\n",
    "from jax_unirep.params import add_dense_params\n",
    "from jax_unirep.layers import mlstm1900, dense\n",
    "from jax_unirep.activations import softmax, identity\n",
    "from jax_unirep.utils import aa_seq_to_int, aa_to_int, load_params_1900\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from jax import grad, jit\n",
    "from jax.experimental.optimizers import adam\n",
    "from typing import List, Dict\n",
    "from jax_unirep.utils import load_embeddings\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_arrs = np.eye(len(aa_to_int))\n",
    "one_hots = {aa_to_int[k]: oh_arrs[i] for i, k in enumerate(aa_to_int.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evotuning_pairs(s: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given a sequence, return input-output pairs for evotuning.\n",
    "    \n",
    "    The goal of evotuning is to get the RNN to accurately predict\n",
    "    the next character in a sequence.\n",
    "    This convenience function exists to prep a single sequence\n",
    "    into its corresponding input-output tensor pairs.\n",
    "    \n",
    "    Given a 1D sequence of length `k`,\n",
    "    it gets represented as a 2D array of shape (k, 10),\n",
    "    where 10 is the size of the embedding of each amino acid,\n",
    "    and k-1 ranges from the zeroth a.a. to the nth a.a.\n",
    "    This is the first element in the returned tuple.\n",
    "    \n",
    "    Given the same 1D sequence,\n",
    "    the output is defined as a 2D array of shape (k-1, 28),\n",
    "    where 28 is the number of possible characters\n",
    "    present in the ``aa_to_int`` dictionary keys,\n",
    "    and k-1 corresponds to the first a.a. to the nth a.a.\n",
    "    This is the second element in the returned tuple.\n",
    "    \n",
    "    :param s: The protein sequence to featurize.\n",
    "    :returns: Two 2D NumPy arrays,\n",
    "        the first corresponding to the input to evotuning with shape (n_letters, 10),\n",
    "        and the second corresponding to the output amino acid to predict with shape (n_letters, 28).\n",
    "    \"\"\"\n",
    "    seq_int = aa_seq_to_int(s[:-1])\n",
    "    next_letters_int = aa_seq_to_int(s[1:])\n",
    "    embeddings = load_embeddings()\n",
    "    x = np.stack([embeddings[i] for i in seq_int])\n",
    "    y = np.stack([one_hots[i] for i in next_letters_int])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def input_output_pairs(sequences: List[str]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate input-output tensor pairs for evo-tuning.\n",
    "    \n",
    "    We check that lengths of sequences are identical,\n",
    "    as this is necessary to ensure stacking of tensors happens correctly.\n",
    "    \n",
    "    :param sequences: A list of sequences \n",
    "        to generate input-output tensor pairs.\n",
    "    :returns: Two NumPy arrays,\n",
    "        the first corresponding to the input to evotuning \n",
    "        with shape (n_sequences, n_letters, 10),\n",
    "        and the second corresponding to the output amino acids to predict \n",
    "        with shape (n_sequences, n_letters, 28).\n",
    "        Both will have an additional \"sample\" dimension as the first dim.\n",
    "    \"\"\"\n",
    "    seqlengths = set(map(len, sequences))\n",
    "    if not len(seqlengths) == 1:\n",
    "        raise ValueError(\"\"\"\n",
    "Sequences should be of uniform length, but are not. \n",
    "Please ensure that they are all of the same length before passing them in.\n",
    "\"\"\")\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for s in sequences:\n",
    "        x, y = evotuning_pairs(s)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.stack(xs), np.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"HASTA\",\n",
    "    \"HASTH\",\n",
    "    \"VISTA\",\n",
    "]\n",
    "\n",
    "x, y = input_output_pairs(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 6, 10), (3, 6, 28))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params[\"mlstm1900\"] = load_params_1900()\n",
    "params = add_dense_params(params, \"dense\", 1900, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(params, x) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Prediction model for evotuning.\n",
    "    \n",
    "    Architecture is a single softmax layer on top of the RNN.\n",
    "    \n",
    "    :param params: Dictionary of parameters.\n",
    "        Should have keys ``mlstm1900`` and ``dense`` in there.\n",
    "    :param x: Input tensor.\n",
    "        Should be the result of calling ``input_output_pairs``,\n",
    "        and be of shape (n_sequences, n_letters, 10).\n",
    "    :returns: Prediction tensor, of shape (n_sequences, n_letters, 28).\n",
    "    \"\"\"\n",
    "    # Defensive programming checks.\n",
    "    if not len(x.shape) == 3:\n",
    "        raise ValueError(\"Input tensor should be 3-dimensional.\")\n",
    "    if not x.shape[-1] == 10:\n",
    "        raise ValueError(\"Input tensor's 3rd dimension should be of length 10.\")\n",
    "\n",
    "    # Actual forward model happens here.\n",
    "    _, _, x = mlstm1900(params[\"mlstm1900\"], x)\n",
    "    x = dense(params[\"dense\"], x, activation=softmax)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_unirep.losses import neg_cross_entropy_loss, mseloss, _neg_cross_entropy_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evotune_loop(params: Dict[str, Dict[str, np.ndarray]], x: np.ndarray, y: np.ndarray, n: int, verbose=False):\n",
    "    \"\"\"\n",
    "    Master function for tuning.\n",
    "\n",
    "    :param x: Input tensor.\n",
    "    :param y: Output tensor to train against.\n",
    "    :param n: Number of epochs (iterations) to train model for.\n",
    "    \"\"\"\n",
    "    # `predict` must be defined in the same source file as this function.\n",
    "    loss = partial(neg_cross_entropy_loss, model=predict)\n",
    "    dloss = jit(grad(loss))\n",
    "\n",
    "    init, update, get_params = adam(step_size=0.005)\n",
    "\n",
    "    state = init(params)\n",
    "    \n",
    "    for i in range(20):\n",
    "        l = loss(params, x=x, y=y)\n",
    "        if np.isnan(l):\n",
    "            break\n",
    "        if verbose:\n",
    "            print(f\"Iteration: {i}, Loss: {l:.4f}\")\n",
    "\n",
    "        g = dloss(params, x=x, y=y)\n",
    "\n",
    "        state = update(i, g, state)\n",
    "        params = get_params(state)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 0.1536\n",
      "Iteration: 1, Loss: 0.0788\n",
      "Iteration: 2, Loss: 0.0362\n",
      "Iteration: 3, Loss: 0.0135\n",
      "Iteration: 4, Loss: 0.0076\n",
      "Iteration: 5, Loss: 0.0081\n",
      "Iteration: 6, Loss: 0.0083\n",
      "Iteration: 7, Loss: 0.0058\n",
      "Iteration: 8, Loss: 0.0061\n",
      "Iteration: 9, Loss: 0.0056\n",
      "Iteration: 10, Loss: 0.0056\n",
      "Iteration: 11, Loss: 0.0057\n",
      "Iteration: 12, Loss: 0.0056\n",
      "Iteration: 13, Loss: 0.0056\n",
      "Iteration: 14, Loss: 0.0055\n",
      "Iteration: 15, Loss: 0.0055\n",
      "Iteration: 16, Loss: 0.0055\n",
      "Iteration: 17, Loss: 0.0055\n",
      "Iteration: 18, Loss: 0.0055\n",
      "Iteration: 19, Loss: 0.0055\n"
     ]
    }
   ],
   "source": [
    "tuned_params = evotune_loop(params, x, y, 20, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUGGING/DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predict(tuned_params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_letter(arr) -> str:\n",
    "    \"\"\"\n",
    "    Convert a 1D one-hot array into a letter.\n",
    "    \n",
    "    TODO: More docstrings needed.\n",
    "    \"\"\"\n",
    "    for k, v in one_hots.items():\n",
    "        if np.allclose(arr, v):\n",
    "            break\n",
    "    for key, val in aa_to_int.items():\n",
    "        if k == val:    \n",
    "            return key\n",
    "\n",
    "def letter_seq(arr: np.array) -> str:\n",
    "    \"\"\"\n",
    "    Convert a 2D one-hot array into a string representation.\n",
    "    \n",
    "    TODO: More docstrings needed.\n",
    "    \"\"\"\n",
    "    sequence = \"\"\n",
    "    for letter in arr:\n",
    "        sequence += arr_to_letter(np.round(letter))\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startASTHstop\n",
      "startASTHstop\n",
      "startISTAstop\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "for seq in y_hat:\n",
    "    sequence = letter_seq(seq)\n",
    "    print(sequence)\n",
    "    sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a;iofle;odvh;ilkjewklfdsshj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"dense\"][\"b\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 239, 1900)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_noaxis(x):\n",
    "    print(x.shape)\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def softmax_newaxis(x):\n",
    "    e = np.exp(batch)\n",
    "    return np.divide(e, np.sum(e, axis=-1)[:, :, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 239, 28)\n"
     ]
    }
   ],
   "source": [
    "_, _, batch = mlstm1900(params[\"mlstm1900\"], x)\n",
    "batch = dense(params[\"dense\"], batch, activation=identity)\n",
    "\n",
    "sfm_noaxis = softmax_noaxis(batch)\n",
    "sfm_newaxis = softmax_newaxis(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = np.exp() / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 239, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-unirep",
   "language": "python",
   "name": "jax-unirep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
